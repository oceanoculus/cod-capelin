---
title: "cod data exploration"
author: "Samantha Andrews"
output: html_notebook
---

# Overview
A note to anyone who might happen to stumble across this... I am a beginner in R and have had no exposure to similar languages. I don't know what I'm doing. The code herein is unlikely to be elegant and there area probably more efficient ways of running the code.

Built with 'r getRversion()'..

# Package dependencies
You can install and load them using the following code which uses a function called [ipak](https://gist.github.com/stevenworthington/3178163). Note this function checks to see if the packages are installed first before loading.

one shot installation
```{r}
install.packages("devtools")
library(devtools)
install_github("iobis/robis")
```


```{r pre-install & load packages, include=FALSE}
packages <- c("rworldmap", "sp", "rgdal", "robis", "raster", "dplyr", "rworldmap", "plyr", "weathermetrics", "ncdf4", "ma")
source("../src/ipak.R")
ipak(packages)
```


download cod data from obis
```{r}
cod <- occurrence("Gadus morhua", startdate = "1998-01-01", enddate = "2015-12-31", geometry = "POLYGON ((-78.22266 65.44000, -32.34375 65.73063, -32.69531 35.88905, -76.99219 36.03133, -78.22266 65.14611, -78.22266 65.44000))")
```

trim to the capelin mcp
```{r}
mcp <- shapefile("../data/bio/minimum_convex_poly/mcp_capelin_100_poly.shp")
plot(mcp)
```

the mcp is in aea format so you will need to reproject the cod data to aea first...

```{r reproject to aea}
xy <- cod[ ,c("decimalLongitude","decimalLatitude")] #3 = decimalLongitude, 2 = decimalLatitude
codsp <- SpatialPointsDataFrame(coords = xy, data = cod, proj4string = CRS("+proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0"))
codsp <- spTransform(codsp, CRS = "+proj=aea +lat_1=50 +lat_2=70 +lat_0=40 +lon_0=-60 +x_0=0 +y_0=0 +ellps=GRS80 +datum=NAD83 +units=m +no_defs") #note -60 used to be -91. Changed to 'straighten up'
plot(codsp)
plot(mcp, add = TRUE)
```


```{r}
codsub <- codsp[mcp, ] #this is just subsetting 
write.csv(codsub, "../data/bio/cod_mcp.csv", row.names = FALSE)
cod <- as.data.frame(codsub)
plot(mcp)
points(codsub)
```

ok lets get rid of a bunch of these columns...


```{r select colums needed}
cod <- read.csv("../data/bio/cod_mcp.csv", header = TRUE)

colnames(cod)

cods <- subset(cod, select = c(id, decimalLatitude, decimalLongitude, year, month, eventDate, institutionCode, individualCount, depth, originalScientificName, collectionCode, lifeStage))
```

remove data without month/year info


```{r}
missingdata <- apply(cods, 2, function (x) sum(is.na(x))) #shows the no of rows missing data in each column
missingdata
```

so year and month are missing for some but event date has all data...
```{r}
datedat <- subset(cods, select = c(year, month, eventDate))
missingmth <- datedat[is.na(datedat$month),]
head(missingmth)
```

ok so only a few do have full date info in eventDate... manually change these
```{r}
cods$month[4208] = 7
cods$month[11845] = 7
cods$month[12153] = 7
```

remove all rows without date information
```{r}
cods <- cods[!is.na(cods$month), ]
missingdata <- apply(cods, 2, function (x) sum(is.na(x))) #shows the no of rows missing data in each column
missingdata
```

now remove all those missing depth information
```{r}
cods <- cods[!is.na(cods$depth), ]
missingdata <- apply(cods, 2, function (x) sum(is.na(x))) #shows the no of rows missing data in each column
write.csv(cods, "../data/bio/cod_mcp.csv", row.names = FALSE)
missingdata
```


#add non-env. data

occurrence indicator
```{r}
cods$occurrence <- "1"
```

 Add NAFO Region occurrence is from
NAFO Zones shapefile obtained from [NAFO](https://www.nafo.int/Data/GIS)

```{r NAFO shapefile extraction}
coordinates(cods) <- c("decimalLongitude", "decimalLatitude") 
nafo_zones <- readOGR(dsn=path.expand("../data/bio/nafo_zones"), layer = "nafo_zones_wgs84") #this loads the shapefile
proj4string(cods) <- proj4string(nafo_zones) #tells R that the occurrence data is the same projection as the shapefile
cods$nafo_zone <- over(cods, nafo_zones)$ZONE #ZONE is where the zone data is held in teh shapefiles' attributes
cods <- as.data.frame(cods)
#check to see if any are missing nafo zones


missingdata <- subset(cods, is.na(cods$nafo_zone))
missingdata
```

ok sot here are 31 missing nafo zones let's look

```{r}
map2 <- getMap(resolution = "low") #creates an object called map at low resoultion
plot(map2, xlim = c(-70, -43), ylim =c(38, 70), asp = 1, main = "Occurences missing a NAFO Zone", col = "cornsilk") #the x and y lim are the long-lat bounds of the map
points(missingdata$decimalLongitude, missingdata$decimalLatitude, col = "red") #this adds points to the mapet", xlab = "Longitude", ylab = "Latitude")
```
ok so some are in the hudson, some are clearly on land...

Start with the Hudson Strait ones as this is easy - anything above 56N, nafo_zone == "HudsonStrait"

```{r}
cods$nafo_zone <- as.character(cods$nafo_zone)
cods[is.na(cods)] <- "xx"
cods$nafo_zone[cods$nafo_zone == "xx" & cods$decimalLatitude > 56] <- "HudsonStrait"
```
and map to check
```{r}
nafo_na <- subset(cods, nafo_zone == "xx")
plot(map2, xlim = c(-70, -43), ylim =c(38, 70), asp = 1, main = "Occurences missing a NAFO Zone", col = "cornsilk") #the x and y lim are the long-lat bounds of the map
points(nafo_na$decimalLongitude, nafo_na$decimalLatitude, col = "red") #this adds points to the mapet", xlab = "Longitude", ylab = "Latitude")
```
so now i need to account for the others (either as occuring on land or just in an area that is missing a NAFO Zone tag) which is more tricky... i might just do this bit in ArcGIS quickly.
```{r}
write.csv(cods, file = "../data/bio/cod_mcp.csv", row.names = FALSE) 
```

so the remaining missing nafo zones indicate points on land. remove
```{r}
cods <- cods[!(cods$nafo_zone == "xx"), ]
write.csv(cods, file = "../data/bio/cod_mcp.csv", row.names = FALSE) 
```


# create a unique cell ID

A unique cell ID layer has been created in the environmental_data_preperation.Rmd. Now you want to extract the value of that layer to the .csv you are creating...

Load the env. data - you can just use the glorys layer or the biomer layer as they are identical
```{r}
cell_layer <- raster("../data/env/unique_cell_lyr/glo_unique_cell.tif") #this is loading the cell layer that was created and saved as a tif
plot(cell_layer)
```

The occurrence data needs to be converted into spatialpoints dataframe
```{r}
xy <- cods[ ,c("decimalLongitude","decimalLatitude")] #3 = decimalLongitude, 2 = decimalLatitude
codsp <- SpatialPointsDataFrame(coords = xy, data = cods, proj4string = CRS("+proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0"))
codsp <- spTransform(codsp, CRS = "+proj=aea +lat_1=50 +lat_2=70 +lat_0=40 +lon_0=-60 +x_0=0 +y_0=0 +ellps=GRS80 +datum=NAD83 +units=m +no_defs") #note -60 used to be -91. Changed to 'straighten up'
```
and plot and Write the transformed species data to a new csv (this will also have the coordinates in meters - note meters are under decimalLongitude1 and decimalLatitude1)...
```{r}
plot(codsp, axes=TRUE, cex.axis=.95)
write.csv(codsp, file = "../data/bio/cod_mcp_aea.csv", row.names = FALSE)
```

Ok now plot the env. and point data  and then extract the cell values
```{r}
plot(cell_layer)
points(codsp$decimalLongitude, codsp$decimalLatitude)
codsp$cell_id <- extract(x=cell_layer, y = codsp)
write.csv(codsp, file = "../data/bio/cod_mcp_aea.csv", row.names = FALSE)
cods <- as.data.frame(codsp)
head(cods)
```

# Add AMO Data

The data has been prepared as per the environmental_data_preperation.Rmd, and biological_data_prep.Rmd in ch1

So you want..
- AMO value at sampling month/year
- AMO value at previous sampling month/year
- AMO phase at previous winter (because the winter values are thought to be a major driver of ocean conditions in the following spring, summer, and autumn)

Load the prepared amo_prev.csv file with has the amo at different year/month steps
```{r}
amo_prev <- read.csv("../data/env/amo_prev.csv", header = TRUE)
```

now match the year and the month in the two dataframes, and populate the background points with amo_sample
```{r}
cods <- merge(x = cods, y = amo_prev[ , c("year", "month", "amo_sample")], by = c("year", "month"), all.x = TRUE)
head(cods)
```

ok next - AMO value at previous sampling month/year 
```{r}
cods <- merge(x = cods, y = amo_prev[ , c("year", "month", "amo_prev")], by = c("year", "month"), all.x = TRUE)
head(cods)
```

and now - AMO phase at previous winter (because the winter values are thought to be a major driver of ocean conditions in the following spring, summer, and autumn) (note they are in a different .csv)

```{r}
amo_winter <- read.csv("../data/env/amo_winter.csv")
cods <- merge(x = cods, y = amo_winter[ , c("year", "WinterAvgShifted")], by = c("year"), all.x = TRUE)
colnames(cods)[colnames(cods)=="WinterAvgShifted"] <- "amo_winter" #change the colname
head(cods)
```

# NAO values
The data has been prepared as per the environmental_data_preperation.Rmd and biological_data_prep.Rmd

So you want..
- NAO value at sampling month/year
- NAO value at previous sampling month/year
- NAO phase at previous winter (because the winter values are thought to be a major driver of ocean conditions in the following spring, summer, and autumn)

Load the prepared nao_prev.csv file with has the amo at different year/month steps
```{r}
nao_prev <- read.csv("../data/env/nao_prev.csv", header = TRUE)
```

now match the year and the month in the two dataframes, and populate the background points with nao_sample

```{r}
cods <- merge(x = cods, y = nao_prev[ , c("year", "month", "nao_sample")], by = c("year", "month"), all.x = TRUE)
```

ok next - NAO value at previous sampling month/year
```{r}
cods <- merge(x = cods, y = nao_prev[ , c("year", "month", "nao_prev")], by = c("year", "month"), all.x = TRUE)
```

and now - NAO phase at previous winter (because the winter values are thought to be a major driver of ocean conditions in the following spring, summer, and autumn). The data is in a different .CSV

```{r}
nao_winter <- read.csv("../data/env/nao_winter.csv")
cods <- merge(x = cods, y = nao_winter[ , c("year", "WinterAvgShifted")], by = c("year"), all.x = TRUE)
colnames(cods)[colnames(cods)=="WinterAvgShifted"] <- "nao_winter" #change the colname
head(cods)
```

and write .csv
```{r}
write.csv(cods,"../data/bio/cod_mcp.csv", row.names = FALSE)
```

#depth layer

the depth layers in the netCDF are literal slices. Currently I have listed the depthlayerno (which is literally which layer in the netcdf). I should also add the depth_layer name which gives the depth the slice is supposed to represent. Data is stored in depth_bin.csv

load the depth bin csv
```{r}
depthbin <- read.csv("../data/env/depth_bin.csv", header = TRUE) 
```

so basically what i want to do is, where depthbin$layer_no = cods$depthlayerno, extract depthbin$layer_name and add to cods$depth_layer. Can use the merge function.
First need to change depthbin col names to match cods

```{r}
names(depthbin)[names(depthbin)=="layer_no"] <- "depthlayerno"
names(depthbin)[names(depthbin)=="layer_name"] <- "depth_layer" #this one is just so i don't have to change the column name in the cods file later
head(depthbin)
```

Now run some fancy if loop (courtesy of [TinglTanglBob] (https://stackoverflow.com/questions/52626995/problem-with-loop-to-add-values-from-one-dataframe-and-to-another-based-on-condi/52627728#52627728))
```{r}
cods$depth <- as.integer(cods$depth)

check_depth <- function(d_temp)
{
  #print(d_temp)
  if(is.na(d_temp)) return(NA) # if d_temp is na just return NA 
  layer_name_temp <- depthbin$layer_name[which(depthbin$bin_min <= d_temp & depthbin$bin_max >= d_temp)]
  if(length(layer_name_temp) > 1) layer_name_temp <- layer_name_temp[1] # in case there are more hits, the first one is taken
  return(layer_name_temp)
}

cods$depth_layer <- sapply(cods$depth, check_depth)
head(cods)
```

ok now dow the same thing to get your layer_no
```{r}
check_depth <- function(d_temp)
{
  #print(d_temp)
  if(is.na(d_temp)) return(NA) # if d_temp is na just return NA 
  layer_no_temp <- depthbin$depthlayerno[which(depthbin$bin_min <= d_temp & depthbin$bin_max >= d_temp)]
  if(length(layer_no_temp) > 1) layer_no_temp <- layer_no_temp[1] # in case there are more hits, the first one is taken
  return(layer_no_temp)
}

cods$depthlayerno <- sapply(cods$depth, check_depth)

write.csv(cods, "../data/bio/cod_mcp.csv", row.names =  FALSE)

```


# observations by cell (in total, and also by time step)

as the title says... how many observations happeend in each cell:
- in total
- in each yyyymm

```{r observation by cell - total}
obs_by_cell <- count(cods, "cell_id")
obs_by_cell
write.csv(obs_by_cell, file = "../data/bio/no_observations_cell.csv")
```


```{r}
obs_cell_yymm <- count(cods, c("cell_id", "year", "month"))
obs_cell_yymm
write.csv(obs_cell_yymm, file = "../data/bio/no_observations_cell_yymm.csv")
```
Now attach these values to cods....

total obs for the whole time period
```{r}
cods <- merge(cods, obs_by_cell, by="cell_id")
head(cods)
```

rename freq column to something meaningful

```{r}
names(cods)[names(cods)=="freq"] <- "total_cell_obs_xy"
head(cods)
```


time-sliced
```{r}
cods <- merge(cods, obs_cell_yymm, by.x=c("cell_id", "year", "month"), by.y=c("cell_id", "year", "month"))
names(cods)[names(cods)=="freq"] <- "total_cell_obs_xyt"
head(cods)
```

time-sliced by depth

```{r}
obs_cell_yymm_depth <- count(cods, c("cell_id", "year", "month", "depthlayerno"))
cods <- merge(cods, obs_cell_yymm_depth, by.x=c("cell_id", "year", "month", "depthlayerno"), by.y=c("cell_id", "year", "month", "depthlayerno"))
names(cods)[names(cods)=="freq"] <- "total_cell_obs_xyzt"
head(cods)
```

write to .csv
```{r}
write.csv(cods,"../data/bio/cod_mcp.csv", row.names = FALSE)
```

#attach oceanographic data
```{r}
cods <- read.csv("../data/bio/cod_mcp.csv", header = TRUE)

cods$temp_depth <- NA
cods$temp_surface <- NA
cods$salinity_depth <- NA
cods$salinity_surface <- NA
cods$chl_depth <- NA
cods$chl_surface <- NA
cods$o2_depth <- NA
cods$o2_surface <- NA
cods$mlp_surface <- NA
cods$ssh_surface <- NA

```

you will be better to do this year by year
```{r}
xy <- cods[ ,c("decimalLongitude.1","decimalLatitude.1")] # This is to tell R where the coordinates are (in column 18 and 19). Note that the column order needs to be longitude, latitude
cod_sp <- SpatialPointsDataFrame(coords = xy, data = cods, proj4string = CRS("+proj=aea +lat_1=50 +lat_2=70 +lat_0=40 +lon_0=-60 +x_0=0 +y_0=0 +ellps=GRS80 +datum=NAD83 +units=m +no_defs")) # The CRS is used here is for the albers equal area projection.


netcdf_list <- list.files("../data/env/netcdf", pattern = '*.nc', full.names = TRUE) #true means the full path is included
no_netcdf <- length(netcdf_list) #for the loop - need to know how many files to cycle through
netcdf_name <- list.files("../data/env/netcdf", pattern = '*.nc', full.names = FALSE) #false means the path is not included
aea <- raster("../data/env/aea.tif") 
for (i in 1:no_netcdf) {  
  print(netcdf_name[i]) #this just prints the name of the netCDF R is working one
  brkyr <- as.integer(sapply(strsplit(netcdf_name[i], "_"), "[[", 1)) # extracting the first part of the netcdf filename (which is the year)
  brkmth <- as.integer(sapply(strsplit(netcdf_name[i], "_"), "[[", 2)) # extracting the second part of the netcdf filename (which is the month)
  brkvar <- (sapply(strsplit(netcdf_name[i], "_"), "[[", 3)) # extracting the third part of the netcdf (inc.nc)
  temp_brick <- brick(netcdf_list[i], lvar = 4)
  temp_brick <- projectRaster(temp_brick, aea) 
    for (j in 1:nrow(cod_sp)) {  
      de <- cod_sp$depthlayerno[[j]]  # a variable for the observation depth layer
      yr <- (cod_sp$year[j])  # a variable for the observation year
      mth <- (cod_sp$month[j])  # a variable for the observation month
          if (brkyr == yr & brkmth == mth & brkvar == "temp.nc"){
              cod_sp$temp_surface[j] <- extract(x=temp_brick[[1]], y = cod_sp[j, ]) 
              if (is.na(de)){
                cod_sp$temp_depth[j] <- NA
              } else  
                cod_sp$temp_depth[j] <- extract(x=temp_brick[[de]], y = cod_sp[j, ])
          } else if (brkyr == yr & brkmth == mth & brkvar == "salinity.nc") {
              cod_sp$salinity_surface[j] <- extract(x=temp_brick[[1]], y = cod_sp[j, ]) 
              if (is.na(de)){
                cod_sp$salinity_depth[j] <- NA
              } else  
                cod_sp$salinity_depth[j] <- extract(x=temp_brick[[de]], y = cod_sp[j, ]) 
          } else if (brkyr == yr & brkmth == mth & brkvar == "chl.nc") {
              cod_sp$chl_surface[j] <- extract(x=temp_brick[[1]], y = cod_sp[j, ]) 
              if (is.na(de)){
                cod_sp$chl_depth[j] <- NA
              } else  
                cod_sp$chl_depth[j] <- extract(x=temp_brick[[de]], y = cod_sp[j, ]) 
          } else if (brkyr == yr & brkmth == mth & brkvar == "o2.nc") {
              cod_sp$o2_surface[j] <- extract(x=temp_brick[[1]], y = cod_sp[j, ]) 
              if (is.na(de)){
                cod_sp$o2_depth[j] <- NA
              } else  
                cod_sp$o2_depth[j] <- extract(x=temp_brick[[de]], y = cod_sp[j, ]) 
          } else if (brkyr == yr & brkmth == mth & brkvar == "mlp.nc") {
              cod_sp$mlp_surface[j] <- extract(x=temp_brick[[1]], y = cod_sp[j, ])
          } else if (brkyr == yr & brkmth == mth & brkvar == "ssh.nc") {
              cod_sp$ssh_surface[j] <- extract(x=temp_brick[[1]], y = cod_sp[j, ]) 
            
          }
     
    }
}

write.csv(cod_sp, "../data/bio/cod_all.csv", row.names = FALSE)

cods <- as.data.frame(cod_sp)
```

#convert kelvin to celsius

```{r}
cods$temp_celsius_depth <- kelvin.to.celsius(cods$temp_depth, round = 4) # 4 is the number of decimal places. the values are expressed to 4
cods$temp_celsius_surface <- kelvin.to.celsius(cods$temp_surface, round = 4)
write.csv(cods, "../data/bio/cod_all.csv", row.names = FALSE)
```

rename lon lat meters columns and remove eventdate

```{r}
names(cods)[names(cods)=="decimalLatitude.1"] <- "latitude_meters" 
names(cods)[names(cods)=="decimalLongitude.1"] <- "longitude_meters" 
cods <- subset(cods, select = -c(eventDate))
colnames(cods)
```

bottom depth from [GEBCO](www.gebco.net)

```{r}
bat <-readGEBCO.bathy("../data/env/GEBCO_2014_2D_-70.0_34.0_-43.0_70.0.nc")
summary(bat)
cods$bottom_depth <- get.depth(bat, cods[ , 7:6], locator = FALSE)
cods$bottom_depth <- cods$bottom_depth[, 3] #this step is because get.bath actually produces it's own dataframe with long, lat, and depth. This is extracting the depth column and deplacing b$bottom_depth with the correct data.
```

add a cell id

```{r cell_id_3d}
cods$cell_id_3d <- paste(cods$cell_id, cods$depthlayerno, sep="_") #create a new column that is a unique cell_id & depth ID.
cods$cell_id_xyzt <- paste(cods$cell_id_3d, cods$year, cods$month, sep="_") #create a new column that is a unique cell_id & depth ID. 
head(cods)
```

#load background points (generated from paper 2...)

```{r}
bk <- read.csv("../data/env/background_all.csv", header = TRUE)
```

compare col headings
```{r}
cn <- colnames(cods)
bn <- colnames(bk)
difn <- setdiff(cn, bn)
difn
```

change cods originalScientificName to all lowercase
```{r}
names(cods)[names(cods)=="originalScientificName"] <- "originalscientificname" 
```

compare col headings (other way round)
```{r}
cn <- colnames(cods)
bn <- colnames(bk)
difn <- setdiff(bn, cn)
difn
```

"institutionCode" "individualCount" "depth" "collectionCode" "lifeStage" all need to be NA in the bkpoints... use rbind.fill

```{r}
codcomp <- rbind.fill(cods, bk)
colnames(codcomp)
write.csv(codcomp, "../data/bio/cod_prab.csv", row.names = FALSE)
```

